{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"/home/work/deeptext/yys/redpen/results/result_readability_newed.json\", \"r\") as f:\n",
    "\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def is_starts_with_num(s):\n",
    "    regex_start_with_1_to_9 = r'^[1-9]'\n",
    "    if re.match(regex_start_with_1_to_9,s) is not None:\n",
    "        return s\n",
    "    else:\n",
    "        return False\n",
    "def is_ends_with_num(string):\n",
    "    regex_end_with_digit = r'\\d$'\n",
    "    if re.search(regex_end_with_digit, string):\n",
    "        return string\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def process_score(score_list):\n",
    "    pattern = r\"[^.\\d]\"\n",
    "    new_scores = []\n",
    "    for i in score_list:\n",
    "        if str(type(i))==\"<class 'int'>\" or str(type(i))==\"<class 'float'>\":\n",
    "            continue\n",
    "        else:\n",
    "            if len(i)>0:\n",
    "                tmp = re.sub(pattern, \"\", i)\n",
    "                if len(tmp)>0 and tmp!=\".\" and is_starts_with_num(tmp) is not False and is_ends_with_num(tmp) is not False and float(tmp)<=5:\n",
    "                    new_scores.append(float(tmp))\n",
    "    if len(new_scores)>0:\n",
    "        return new_scores\n",
    "    else:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4.5, 3.5, 4.5, 4.5, 4.5]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_score(['4.5', '3.5', '4.5', '4.5', '4.5'])\n",
    "pattern = r\"[^.\\d]\"\n",
    "new_scores = []\n",
    "\n",
    "for i in ['4.5', '3.5', '4.5', '4.5', '4.5']:\n",
    "    tmp = re.sub(pattern,\"\",i)\n",
    "    if len(tmp)>0 and tmp!=\".\" and is_starts_with_num(tmp) is not False and is_ends_with_num(tmp) is not False and float(tmp)<=5:\n",
    "        new_scores.append(float(tmp))\n",
    "new_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'response': 'The American state that is nicknamed the Treasure State is Montana.',\n",
       " 'grammar': [5.0, 5.0, 5.0, 5.0, 5.0],\n",
       " 'completeness': [5.0, 5.0, 5.0, 5.0, 5.0],\n",
       " 'readability': ['4', '35', '4', '4.5', '4'],\n",
       " 'grammar_avg': 5.0,\n",
       " 'completeness_avg': 5.0,\n",
       " 'readability_avg': 5.0}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]['gpt-3.5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4.0, 4.0, 4.5, 4.0]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_score(['4', '35', '4', '4.5', '4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for datum in data:\n",
    "    try: \n",
    "        datum['gpt-3.5']['readability'] = process_score(datum['gpt-3.5']['readability'])\n",
    "    except:\n",
    "        print(datum['gpt-3.5']['readability'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'float' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 9\u001b[0m\n\u001b[1;32m      3\u001b[0m new_list \u001b[39m=\u001b[39m []\n\u001b[1;32m      4\u001b[0m \u001b[39mfor\u001b[39;00m datum \u001b[39min\u001b[39;00m data:\n\u001b[1;32m      5\u001b[0m         new_dict \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39midx\u001b[39m\u001b[39m'\u001b[39m:datum[\u001b[39m'\u001b[39m\u001b[39midx\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m      6\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39mquestion\u001b[39m\u001b[39m'\u001b[39m:datum[\u001b[39m'\u001b[39m\u001b[39mquestion\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m      7\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39mq_len\u001b[39m\u001b[39m'\u001b[39m:datum[\u001b[39m'\u001b[39m\u001b[39mq_len\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m      8\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39mgpt-4\u001b[39m\u001b[39m'\u001b[39m:{\u001b[39m'\u001b[39m\u001b[39mresponse\u001b[39m\u001b[39m'\u001b[39m:datum[\u001b[39m'\u001b[39m\u001b[39mgpt-4\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mresponse\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[0;32m----> 9\u001b[0m                         \u001b[39m'\u001b[39m\u001b[39mgrammar\u001b[39m\u001b[39m'\u001b[39m:process_score(datum[\u001b[39m'\u001b[39;49m\u001b[39mgpt-4\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m'\u001b[39;49m\u001b[39mgrammar\u001b[39;49m\u001b[39m'\u001b[39;49m]),\n\u001b[1;32m     10\u001b[0m                         \u001b[39m'\u001b[39m\u001b[39mcompleteness\u001b[39m\u001b[39m'\u001b[39m:process_score(datum[\u001b[39m'\u001b[39m\u001b[39mgpt-4\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mcompleteness\u001b[39m\u001b[39m'\u001b[39m]),\n\u001b[1;32m     11\u001b[0m                         \u001b[39m'\u001b[39m\u001b[39mreadability\u001b[39m\u001b[39m'\u001b[39m:process_score(datum[\u001b[39m'\u001b[39m\u001b[39mgpt-4\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mreadability\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     12\u001b[0m                         },\n\u001b[1;32m     13\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39mgpt-3.5\u001b[39m\u001b[39m'\u001b[39m:{\u001b[39m'\u001b[39m\u001b[39mresponse\u001b[39m\u001b[39m'\u001b[39m:datum[\u001b[39m'\u001b[39m\u001b[39mgpt-3.5\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mresponse\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m     14\u001b[0m                         \u001b[39m'\u001b[39m\u001b[39mgrammar\u001b[39m\u001b[39m'\u001b[39m:process_score(datum[\u001b[39m'\u001b[39m\u001b[39mgpt-3.5\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mgrammar\u001b[39m\u001b[39m'\u001b[39m]),\n\u001b[1;32m     15\u001b[0m                         \u001b[39m'\u001b[39m\u001b[39mcompleteness\u001b[39m\u001b[39m'\u001b[39m:process_score(datum[\u001b[39m'\u001b[39m\u001b[39mgpt-3.5\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mcompleteness\u001b[39m\u001b[39m'\u001b[39m]),\n\u001b[1;32m     16\u001b[0m                         \u001b[39m'\u001b[39m\u001b[39mreadability\u001b[39m\u001b[39m'\u001b[39m:process_score(datum[\u001b[39m'\u001b[39m\u001b[39mgpt-3.5\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mreadability\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     17\u001b[0m                         },\n\u001b[1;32m     18\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39mllama2\u001b[39m\u001b[39m'\u001b[39m:{\u001b[39m'\u001b[39m\u001b[39mresponse\u001b[39m\u001b[39m'\u001b[39m:datum[\u001b[39m'\u001b[39m\u001b[39mllama2\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mresponse\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m     19\u001b[0m                         \u001b[39m'\u001b[39m\u001b[39mgrammar\u001b[39m\u001b[39m'\u001b[39m:process_score(datum[\u001b[39m'\u001b[39m\u001b[39mllama2\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mgrammar\u001b[39m\u001b[39m'\u001b[39m]),\n\u001b[1;32m     20\u001b[0m                         \u001b[39m'\u001b[39m\u001b[39mcompleteness\u001b[39m\u001b[39m'\u001b[39m:process_score(datum[\u001b[39m'\u001b[39m\u001b[39mllama2\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mcompleteness\u001b[39m\u001b[39m'\u001b[39m]),\n\u001b[1;32m     21\u001b[0m                         \u001b[39m'\u001b[39m\u001b[39mreadability\u001b[39m\u001b[39m'\u001b[39m:process_score(datum[\u001b[39m'\u001b[39m\u001b[39mllama2\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mreadability\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     22\u001b[0m                         },\n\u001b[1;32m     23\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39mdolly_v2\u001b[39m\u001b[39m'\u001b[39m:{\u001b[39m'\u001b[39m\u001b[39mresponse\u001b[39m\u001b[39m'\u001b[39m:datum[\u001b[39m'\u001b[39m\u001b[39mdolly_v2\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mresponse\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m     24\u001b[0m                         \u001b[39m'\u001b[39m\u001b[39mgrammar\u001b[39m\u001b[39m'\u001b[39m:process_score(datum[\u001b[39m'\u001b[39m\u001b[39mdolly_v2\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mgrammar\u001b[39m\u001b[39m'\u001b[39m]),\n\u001b[1;32m     25\u001b[0m                         \u001b[39m'\u001b[39m\u001b[39mcompleteness\u001b[39m\u001b[39m'\u001b[39m:process_score(datum[\u001b[39m'\u001b[39m\u001b[39mdolly_v2\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mcompleteness\u001b[39m\u001b[39m'\u001b[39m]),\n\u001b[1;32m     26\u001b[0m                         \u001b[39m'\u001b[39m\u001b[39mreadability\u001b[39m\u001b[39m'\u001b[39m:process_score(datum[\u001b[39m'\u001b[39m\u001b[39mdolly_v2\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mreadability\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     27\u001b[0m                         }}\n\u001b[1;32m     28\u001b[0m         new_list\u001b[39m.\u001b[39mappend(new_dict)\n",
      "Cell \u001b[0;32mIn[22], line 20\u001b[0m, in \u001b[0;36mprocess_score\u001b[0;34m(score_list)\u001b[0m\n\u001b[1;32m     18\u001b[0m new_scores \u001b[39m=\u001b[39m []\n\u001b[1;32m     19\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m score_list:\n\u001b[0;32m---> 20\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39;49m(i)\u001b[39m>\u001b[39m\u001b[39m0\u001b[39m:\n\u001b[1;32m     21\u001b[0m         tmp \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(pattern, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m, i)\n\u001b[1;32m     22\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(tmp)\u001b[39m>\u001b[39m\u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m tmp\u001b[39m!=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m is_starts_with_num(tmp) \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mFalse\u001b[39;00m \u001b[39mand\u001b[39;00m is_ends_with_num(tmp) \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mFalse\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mfloat\u001b[39m(tmp)\u001b[39m<\u001b[39m\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m:\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'float' has no len()"
     ]
    }
   ],
   "source": [
    "models = ['gpt-4','llama2','gpt-3.5','dolly_v2']\n",
    "critics = ['grammar','completeness','readability']\n",
    "new_list = []\n",
    "for datum in data:\n",
    "        new_dict = {'idx':datum['idx'],\n",
    "                'question':datum['question'],\n",
    "                'q_len':datum['q_len'],\n",
    "                'gpt-4':{'response':datum['gpt-4']['response'],\n",
    "                        'grammar':process_score(datum['gpt-4']['grammar']),\n",
    "                        'completeness':process_score(datum['gpt-4']['completeness']),\n",
    "                        'readability':process_score(datum['gpt-4']['readability'])\n",
    "                        },\n",
    "                'gpt-3.5':{'response':datum['gpt-3.5']['response'],\n",
    "                        'grammar':process_score(datum['gpt-3.5']['grammar']),\n",
    "                        'completeness':process_score(datum['gpt-3.5']['completeness']),\n",
    "                        'readability':process_score(datum['gpt-3.5']['readability'])\n",
    "                        },\n",
    "                'llama2':{'response':datum['llama2']['response'],\n",
    "                        'grammar':process_score(datum['llama2']['grammar']),\n",
    "                        'completeness':process_score(datum['llama2']['completeness']),\n",
    "                        'readability':process_score(datum['llama2']['readability'])\n",
    "                        },\n",
    "                'dolly_v2':{'response':datum['dolly_v2']['response'],\n",
    "                        'grammar':process_score(datum['dolly_v2']['grammar']),\n",
    "                        'completeness':process_score(datum['dolly_v2']['completeness']),\n",
    "                        'readability':process_score(datum['dolly_v2']['readability'])\n",
    "                        }}\n",
    "        new_list.append(new_dict)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7487"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['gpt-4','llama2','gpt-3.5','dolly_v2']\n",
    "critics = ['grammar','completeness','readability']\n",
    "index_to_remove = []\n",
    "for datum in data:\n",
    "    for model in models:\n",
    "        for critic in critics:\n",
    "            if len(datum[model][critic])==0:\n",
    "                index_to_remove.append(datum['idx'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in reversed(index_to_remove):\n",
    "    data.pop(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data)):\n",
    "    data[i]['idx'] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6817"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def response_process(text):\n",
    "    text = re.sub('[^a-zA-Z~!@#$%^&*()_+|<>?:{}.,; ]', '', text)\n",
    "    if len(text.split())<3:\n",
    "        print(text)\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "response_process('hi, my name is yys.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['gpt-4','llama2','gpt-3.5','dolly_v2']\n",
    "\n",
    "index_to_remove = []\n",
    "\n",
    "for datum in data:\n",
    "    for model in models:\n",
    "        text = datum[model]['response']\n",
    "        if not response_process(text):\n",
    "            index_to_remove.append(datum['idx'])          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_to_remove = list(set(index_to_remove))\n",
    "len(index_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7531"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_to_remove.sort()\n",
    "for i in reversed(index_to_remove):\n",
    "    new_list.pop(i)\n",
    "for i in range(len(new_list)):\n",
    "    new_list[i]['idx'] = i\n",
    "len(new_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "for datum in data:\n",
    "    for model in models:\n",
    "        for critic in critics:\n",
    "            new_name = critic+'_avg'\n",
    "            datum[model][new_name] = np.mean(datum[model][critic])\n",
    "            #datum[model][new_name] = np.mean(sorted(datum[model][critic][:3],reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/work/.local/miniconda3/envs/yys/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "/home/work/.local/miniconda3/envs/yys/lib/python3.9/site-packages/transformers/convert_slow_tokenizer.py:470: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "model = AutoModel.from_pretrained(\"microsoft/deberta-v3-large\")\n",
    "tokenizer = AutoTokenizer.from_pretrained('microsoft/deberta-v3-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_len(text):\n",
    "    l = tokenizer.tokenize(text)\n",
    "    if len(l)>256:\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_remove = []\n",
    "for datum in new_list:\n",
    "    for model in models:\n",
    "        if not calc_len(datum[model]['response']):\n",
    "            index_to_remove.append(datum['idx'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_remove = list(set(index_to_remove))\n",
    "index_to_remove.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7487"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in reversed(index_to_remove):\n",
    "    new_list.pop(i)\n",
    "for i in range(len(new_list)):\n",
    "    new_list[i]['idx'] = i\n",
    "len(new_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/work/deeptext/yys/redpen/data/data_final_g3.json\", \"w\", encoding='utf-8') as f:\n",
    "    json.dump(data,f , ensure_ascii=False,indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yys",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b414fc1e9b01ec0e3104513ada18687df2a6952cdc4efdeda01cb7a7dbe427c8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
