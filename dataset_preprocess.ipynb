{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[1;32m      3\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_parquet(\u001b[39m\"\u001b[39m\u001b[39m/home/work/deeptext/yys/redpen/data/1M-GPT4-Augmented.parquet\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[39m# df = df.to_json(orient=\"records\")\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_parquet(\"/home/work/deeptext/yys/redpen/data/1M-GPT4-Augmented.parquet\")\n",
    "# df = df.to_json(orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9734c5785894427b400bdc2f345f0f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45c84304e087401a9c53931c98586005",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/580 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12b58d1f3e394cc38ea2202735808829",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.35M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/deberta-v3-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_len(st):\n",
    "    return len(tokenizer.tokenize(st))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_json('/home/work/deeptext/yys/redpen/data/1M-GPT4-Augmented.json',orient=\"columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"/home/work/deeptext/yys/redpen/data/1M-GPT4-Augmented.json\", \"r\") as f:\n",
    "\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# id, system_prompt, question, response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "994896"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data['response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You will be given a definition of a task first, then some input of the task.\\nThis task is about using the specified sentence and converting the sentence to Resource Description Framework (RDF) triplets of the form (subject, predicate object). The RDF triplets generated must be such that the triplets accurately capture the structure and semantics of the input sentence. The input is a sentence and the output is a list of triplets of the form [subject, predicate, object] that capture the relationships present in the sentence. When a sentence has more than 1 RDF triplet possible, the output must contain all of them.\\n\\nAFC Ajax (amateurs)'s ground is Sportpark De Toekomst where Ajax Youth Academy also play.\\nOutput:\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['question']['0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 994896/994896 [29:50<00:00, 555.58it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "res_list = []\n",
    "for i in tqdm(range(len(data['question']))):\n",
    "    tmp_dict = {}\n",
    "    tmp_dict['idx'] = i\n",
    "    tmp_dict['question'] = None\n",
    "    tmp_dict['response'] = None\n",
    "    idx = str(i)\n",
    "    q_len = calc_len(data['question'][idx])\n",
    "    r_len = calc_len(data['response'][idx])\n",
    "    if q_len+r_len >200:\n",
    "        continue\n",
    "    else:\n",
    "        tmp_dict['question'] = data['question'][idx]\n",
    "        tmp_dict['response'] = data['response'][idx]\n",
    "        res_list.append(tmp_dict)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "386461"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(res_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"/home/work/deeptext/yys/redpen/data/gpt4_augmented_length_200.json\", \"w\", encoding='utf-8') as f:\n",
    "    json.dump(res_list,f , ensure_ascii=False,indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"/home/work/deeptext/yys/redpen/data/gpt4_augmented_length_200.json\", \"r\") as f:\n",
    "\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, datum in enumerate(data):\n",
    "    datum['idx'] = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_eng(text):\n",
    "    pattern = re.compile(r\"[^a-zA-Z0-9!!\\\"#$%&'()*+,-./:;<=>?@\\[\\]\\s]\")\n",
    "    t = re.sub(pattern, '',text)\n",
    "    if len(text)==len(t):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9999\r"
     ]
    }
   ],
   "source": [
    "from tqdm import  tqdm\n",
    "from random import  *\n",
    "import re\n",
    "\n",
    "new_data = list()\n",
    "\n",
    "i = 0\n",
    "while len(new_data)<10000:\n",
    "    tnum = randint(1,386460)\n",
    "    if is_eng(data[tnum]['question']) and is_eng(data[tnum]['response']):\n",
    "        tdict = dict()\n",
    "        tdict['idx'] = i\n",
    "        tdict['question'] = None\n",
    "        tdict['gpt-4'] = {'response':None, \n",
    "                        'grammar':None,\n",
    "                        'completeness':None,\n",
    "                        'Readability':None}\n",
    "        tdict['gpt-3.5'] = {'response':None, \n",
    "                        'grammar':None,\n",
    "                        'completeness':None,\n",
    "                        'Readability':None}\n",
    "        tdict['flan-paca'] = {'response':None, \n",
    "                        'grammar':None,\n",
    "                        'completeness':None,\n",
    "                        'Readability':None}\n",
    "        tdict['dolly-v2'] = {'response':None, \n",
    "                        'grammar':None,\n",
    "                        'completeness':None,\n",
    "                        'Readability':None}\n",
    "        tdict['question']=data[tnum]['question']\n",
    "        tdict['gpt-4']['response']=data[tnum]['response']\n",
    "        new_data.append(tdict)\n",
    "        print(i, end='\\r')\n",
    "        i+=1\n",
    "    else:\n",
    "        continue\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_data)\n",
    "# new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"/home/work/deeptext/yys/redpen/data/data_sampled_10k_only_eng.json\", \"w\", encoding='utf-8') as f:\n",
    "    json.dump(new_data,f , ensure_ascii=False,indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"/home/work/deeptext/yys/redpen/data/data_sampled_10k_only_eng_dolly_finished.json\", \"r\") as f:\n",
    "\n",
    "    dolly = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'response': '...................... 4 \"Like\"................................ 3 \"Neutral\".......................... 2 \"Dislike\".......................... 1 \"Hate\"............................. 0  Thank you for your feedback. We appreciate it!  ',\n",
       " 'grammar': None,\n",
       " 'completeness': None,\n",
       " 'readability': None}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dolly[0]['dolly_v2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'idx': 0,\n",
       " 'question': 'On a scale of 1-5 (with 1 being least favorable and 5 being most favorable), how would you rate this review? \"Love\" ',\n",
       " 'q_len': 30,\n",
       " 'gpt-4': {'response': '2',\n",
       "  'grammar': None,\n",
       "  'completeness': None,\n",
       "  'readability': None},\n",
       " 'llama2': {'response': \"Thank you for sharing your feedback with us! We are thrilled to hear that you had an amazing experience at our restaurant. Your positive review is greatly appreciated, and we will continue to work hard to provide excellent service and food quality to all of our guests. If there's anything else we can assist you with, please don't hesitate to reach out.\",\n",
       "  'grammar': None,\n",
       "  'completeness': None,\n",
       "  'readability': None},\n",
       " 'flan-paca': {'response': None,\n",
       "  'grammar': None,\n",
       "  'completeness': None,\n",
       "  'readability': None},\n",
       " 'dolly_v2': {'response': '...................... 4 \"Like\"................................ 3 \"Neutral\".......................... 2 \"Dislike\".......................... 1 \"Hate\"............................. 0  Thank you for your feedback. We appreciate it!  ',\n",
       "  'grammar': None,\n",
       "  'completeness': None,\n",
       "  'readability': None},\n",
       " 'gpt-3.5': {'response': 'I\\'m sorry, but it seems like you have only provided the word \"Love\" without any context or additional information. In order to accurately assess and rate a review, I would need more details or the full content of the review to consider.',\n",
       "  'grammar': None,\n",
       "  'completeness': None,\n",
       "  'readability': None}}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dolly[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_d = 0\n",
    "l_g4 = 0\n",
    "l_g3 = 0\n",
    "l_ll = 0\n",
    "for datum in dolly:\n",
    "    l_d+=len(datum['dolly_v2']['response'].split())\n",
    "    l_g4+=len(datum['gpt-4']['response'].split())\n",
    "    l_g3+=len(datum['gpt-3.5']['response'].split())\n",
    "    l_ll+=len(datum['llama2']['response'].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_d//10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_g4//10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_g3//10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_ll//10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for datum in dolly:\n",
    "    datum['gpt-3.5'] = {'response':datum['gpr-3.5']['response'][0],\n",
    "                        'grammar':None,\n",
    "                        'completeness':None,\n",
    "                        'readability':None}\n",
    "    datum.pop('gpr-3.5')\n",
    "    datum['dolly_v2']['response'] = datum['dolly_v2']['response'].replace('\\t','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/work/deeptext/yys/redpen/data/data_sampled_10k_only_eng_dolly_finished.json\", \"w\", encoding='utf-8') as f:\n",
    "    json.dump(dolly,f , ensure_ascii=False,indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ec8e99decc2081de849a29470fa13db5bdc133f36de876237d16680bb689c064"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
